<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="In this work, we reveal the generalization-to-memorization collapse in the self-consuming loop of diffusion models, and show the relationship between generalization ability and the entropy of the training data. Based on the analysis, we propose data selection methods to mitigate this problem.">
  <meta property="og:title" content="A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective"/>
  <meta property="og:description" content="In this work, we reveal the generalization-to-memorization collapse in the self-consuming loop of diffusion models, and show the relationship between generalization ability and the entropy of the training data. Based on the analysis, we propose data selection methods to mitigate this problem."/>
  <meta property="og:url" content="https://shilianghe007.github.io//model-collapse/index.html"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/pipeline.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective">
  <meta name="twitter:description" content="In this work, we reveal the generalization-to-memorization collapse in the self-consuming loop of diffusion models, and show the relationship between generalization ability and the entropy of the training data. Based on the analysis, we propose data selection methods to mitigate this problem.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/pipeline.png">
  <meta name="twitter:card" content="A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="diffusion Model, model collapse, generalization, entropy, data selection">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Model Collapse</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/reproducibility.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js">
  </script>

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://shilianghe007.github.io/" target="_blank">Lianghe Shi</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Meng_Wu3" target="_blank">Meng Wu</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://www.huijiezh.com/" target="_blank">Huijie Zhang,</a>
              <span class="author-block">
                <a href="https://la0ka1.github.io/" target="_blank">Zekai Zhang,</a>
              <span class="author-block">
                <a href="https://mtao8.math.gatech.edu/" target="_blank">Molei Tao,</a>
              <span class="author-block">
                <a href="https://qingqu.engin.umich.edu/" target="_blank">Qing Qu</a>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Department of Electrical and Computer Engineering, University of Michigan<br>School of Mathematics, Georgia Institute of Technology<br><b>NeurIPS 2025</b> (<b style="color: #3e24bf">Spotlight</b>)<br><b>ICML 2025 Workshop</b> (<b style="color: #C70039">Oral</b>)</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2509.16499" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>ArXiv</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/shilianghe007/Model_Collapse" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.21088" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


<!-- Teaser video-->
<section class="hero teaser">
  
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/pipeline.png" alt="MY ALT TEXT"/>
       <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">
        <b>High-level depiction of the self-consuming pipeline.</b> <b>Top:</b> <i>Collapse iteration</i> represents the replace paradigm where models are trained solely on synthetic images generated by the previous diffusion model. <b>Middle:</b> In the <i>mitigated iteration</i>, original real data and previously generated data are added to train the next-generation model. Our proposed <span style="color: #ff69b4;">selection methods</span> construct a training subset and can further mitigate collapse. <b>Bottom Right:</b> Evolution of the generated images.
      </div>
    </div>
  </div>
</section>

<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The widespread use of diffusion models has led to an abundance of AI-generated data, raising concerns about \textit{model collapse}---a phenomenon in which recursive iterations of training on synthetic data lead to performance degradation. Prior work primarily characterizes this collapse via variance shrinkage or distribution shift, but these perspectives miss practical manifestations of model collapse. This paper identifies a transition from generalization to memorization during model collapse in diffusion models, where models increasingly replicate training data instead of generating novel content during iterative training on synthetic samples. This transition is directly driven by the declining entropy of the synthetic training data produced in each training cycle, which serves as a clear indicator of model degradation. Motivated by this insight, we propose an entropy-based data selection strategy to mitigate the transition from generalization to memorization and alleviate model collapse. Empirical results show that our approach significantly enhances visual quality and diversity in recursive generation, effectively preventing collapse.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero teaser">
  
  <div class="container is-max-desktop">
    <div class="hero-body" >
      
      <div style="text-align: center;">
        <div style="margin-top: 40px;"></div>
        <h2 class="title is-3">Model Collapses from Generalization to Memorization</h2>
        <hr/>
        <img src="static/images/Gen_score.png" width="800px"/>
        <!-- <img src="static/images/robustness_consistency_tradeoff.jpg" width="800px"/> -->
        <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">
          <b>The generalization-to-memorization transition.</b>
          <b>Left:</b> visualization of the generated images (<i>&#x1D4A2;<sub>n</sub></i>) and their nearest neighbors in the training dataset (<i>&#x1D4B4;<sub>n</sub></i>). 
          As the iteration proceeds, the model can only copy images from the training dataset. 
          <b>Right:</b> quantitative results of the generalization score of models over successive iterations. 
          We use different colors to represent different dataset sizes. 
          We use “iteration” to denote a full cycle of training and generation, rather than a gradient update.
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" >
      <div style="text-align: center;">
        <h2 class="title is-3">The Relationship between <br> Generalization Score and Entropy</h2>
        <hr/>
        <div style="display: flex; justify-content: center; gap: 20px;">
          <img src="static/images/gen_vs_entropy.png" width="400px"/>
          <img src="static/images/gen_vs_variance.png" width="400px"/>
        </div>
        <!-- <img src="static/images/robustness_consistency_tradeoff.jpg" width="800px"/> -->
        <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">
          <b>Scatter plots</b> of the generalization score and properties of the training dataset, i.e., entropy and variance. Each point denotes one iteration of training in the self-consuming loop. We use different colors to represent the results of different dataset sizes.
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" >
      <div style="text-align: center;">
        <h2 class="title is-3">Mitigating Collapse via Data Selection Methods</h2>
        <hr/>
        <div style="text-align: left; font-size: 1.1em; color: #444; margin-top: 10px;">
          Since we have shown that the decaying entropy leads to the collapsing generalization performance, we propose two data selection methods to mitigate model collapse by approximately maximizing the entropy of the training dataset.
        </div>
        <div style="text-align: center;">
          <img src="static/images/max_entropy.png" width="480px"/>
        </div>
        <div style="text-align: left; font-size: 1.1em; color: #444; margin-top: 10px;">
          The pseudo-codes of the two methods:
        </div>
        <div style="text-align: center;">
          <img src="static/images/pseudo-code-greedy_selection.png" width="800px"/>
          <img src="static/images/pseudo-code-TDF.png" width="800px"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  
  <div class="container is-max-desktop">
    <div class="hero-body" >
      
      <div style="text-align: center;">
        <div style="margin-top: 20px;"></div>
        <h2 class="title is-3">Experiments</h2>
        <hr/>
        <img src="static/images/combined_Gen_plots_independent_y.png" width="800px"/>
        <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">  
          <b>Generalization Score of the trained model over iterations.</b> We indicate the settings on top of the subfigures. In each subfigure, three different lines are used to represent the vanilla paradigm and its variants augmented with the proposed selection methods.
        </div>
        <hr/>
        <img src="static/images/combined_FID_plots_independent_y.png" width="800px"/>
        <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">  
          <b>FID of the generated images over iterations.</b> We indicate the settings on top of the subfigures. In each subfigure, three different lines are used to represent the vanilla paradigm and its variants augmented with the proposed selection methods.
        </div>

        <hr/>
        <img src="static/images/combined_entropy_plots_independent_y.png" width="800px"/>
        <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">  
          <b>Estimated entropy of the training dataset over iterations.</b> We indicate the settings on top of the subfigures. In each subfigure, three different lines are used to represent the vanilla paradigm and its variants augmented with the proposed selection methods.
        </div>
        <hr/>
        <img src="static/images/ratios_ffhq_cifar.png" width="800px"/>
        <div style="font-size: 1.1em; text-align: left; margin-top: 10px; color: #444;">  
          <strong>Proportion of the selected images</strong> from previous iterations or the real dataset. We use different colors to represent different sources. In particular, the blue bars denote the proportion of the real images. The red line represents the \(1/n\) curve that indicates the proportion of the real images if we evenly select the data subset from all available images (accumulate-subsample). We indicate the settings on top of the subfigures.
        </div>
      </div>
    </div>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{shi2025modelcollapse,
        title={A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective},
        author={Shi, Lianghe and Wu, Meng and Zhang, Huijie and Zhang, Zekai and Tao, Molei and Qu, Qing},
        journal={arXiv preprint arXiv:2509.16499},
        year={2025}}</code></pre>
    </div>
  </section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the contents of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
